{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import json\n",
    "import urllib2\n",
    "from time import sleep\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN_POS_PAIR = pd.read_pickle('./NN_POS_PAIR')\n",
    "NV_POS_PAIR = pd.read_pickle('./NV_POS_PAIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# 要增加 pos 認識的 term 請在這裏\n",
    "# ex: dff_soup 要多認識一個名詞 '濃稠度\n",
    "#'data = { 'NPOS': np.array(['dft_soup']), 'NTERM': np.array(['濃稠度])}  \n",
    "# NN_POS_PAIR = NN_POS_PAIR.append(pd.DataFrame(data),ignore_index=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize word2vector model\n",
    "model=gensim.models.Word2Vec.load_word2vec_format('../02_Word2Vector/bin/mobile01_ptt.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 資料觀察用, 儲存 word2vector 失敗的的 term\n",
    "ptt_no_data = []\n",
    "for idx in range(len(NN_POS_PAIR)):\n",
    "    NN_NPOS = NN_POS_PAIR['NPOS'][idx]\n",
    "    NN_NTERM= NN_POS_PAIR['NTERM'][idx]\n",
    "    #print NN_NPOS + '\\t' + repr(NN_NTERM).decode('unicode-escape')\n",
    "    try:\n",
    "        w2v_result = model.most_similar(NN_NTERM)\n",
    "        \n",
    "    except KeyError:\n",
    "        # ERROR HANDLEING...SAVE THOSE TERM AS KNOWLEDGE\n",
    "        print 'Oops!  [' + str(idx) +']\\t' + repr(NN_NTERM).decode('unicode-escape') + 'is not work in word2vector'\n",
    "        ptt_no_data.append(NN_NTERM)\n",
    "        continue\n",
    "        \n",
    "    # FOR DATA OBSERVATION...\n",
    "    pp = pd.DataFrame(np.array(w2v_result))\n",
    "    pos_numpy = pd.DataFrame.as_matrix(pp)\n",
    "    DATA_STATISTIC_RESHAPE = pd.DataFrame(pos_numpy.reshape(2,-1))\n",
    "    #print DATA_STATISTIC_RESHAPE  \n",
    "    \n",
    "#儲存 failed term\n",
    "# PTT_NO_DATA_LIST = pd.DataFrame(ptt_no_data)\n",
    "# PTT_NO_DATA_LIST.to_pickle('./PTT_NO_DATA_N-LIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 延伸所有的 n\n",
    "exception_case = [u'鼎泰豐']\n",
    "ptt_no_data = []\n",
    "NN_POS_PAIR_EXT = NN_POS_PAIR\n",
    "for idx in range(len(NN_POS_PAIR)):\n",
    "    NN_NPOS = NN_POS_PAIR['NPOS'][idx]\n",
    "    NN_NTERM= NN_POS_PAIR['NTERM'][idx]\n",
    "    #有些已知 word2vector找出來效果很差的就跳過\n",
    "    if NN_NTERM in exception_case:\n",
    "        continue\n",
    "    #print NN_NPOS + '\\t' + repr(NN_NTERM).decode('unicode-escape')\n",
    "    try:\n",
    "        w2v_result = model.most_similar(NN_NTERM)\n",
    "        \n",
    "    except KeyError:\n",
    "        # 還是會有錯誤的,但是這裏就不處理了\n",
    "        #print 'Oops!  [' + str(idx) +']\\t' + repr(NN_NTERM).decode('unicode-escape') + 'is not work in word2vector'\n",
    "        #ptt_no_data.append(NN_NTERM)\n",
    "        continue\n",
    "    # Expansion data\n",
    "    w2v_np_result = np.array(w2v_result)\n",
    "    w2v_np_result = w2v_np_result[:,0] #刪除成績部分,只留下term\n",
    "    data = {'NPOS': np.array([NN_POS_PAIR['NPOS'][idx]]*10),'NTERM':w2v_np_result}\n",
    "    NN_POS_PAIR_EXT = NN_POS_PAIR_EXT.append(pd.DataFrame(data),ignore_index=True)  \n",
    "    #print DATA_STATISTIC_RESHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/ipykernel/__main__.py:5: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#刪除重複元素909->861,然後儲存\n",
    "print len(NN_POS_PAIR_EXT)\n",
    "NN_POS_PAIR_EXT = NN_POS_PAIR_EXT.drop_duplicates()\n",
    "print len(NN_POS_PAIR_EXT)\n",
    "NN_POS_PAIR_EXT.sort(['NPOS','NTERM'],ascending=[1,1])\n",
    "NN_POS_PAIR_EXT.to_pickle('./NN_POS_PAIR_EXT') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "# 以下爲測試code\n",
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 單一 term 測試 word2vector\n",
    "NN_NPOS = NN_POS_PAIR['NPOS'][2]\n",
    "NN_NTERM= NN_POS_PAIR['NTERM'][2]\n",
    "print NN_NPOS + '\\t' + repr(NN_NTERM).decode('unicode-escape')\n",
    "w2v_result = model.most_similar(NN_NTERM)\n",
    "pp = pd.DataFrame(np.array(w2v_result))\n",
    "pos_numpy = pd.DataFrame.as_matrix(pp)\n",
    "DATA_STATISTIC_RESHAPE = pd.DataFrame(pos_numpy.reshape(2,-1))\n",
    "DATA_STATISTIC_RESHAPE\n",
    "#exception_case = ['鼎泰豐']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#測試延伸 data frame\n",
    "w2v_np_result = np.array(w2v_result)\n",
    "w2v_np_result = w2v_np_result[:,0] #刪除成績部分,只留下term\n",
    "data = {'NPOS': np.array(['fooe']*10),'NTERM':w2v_np_result}\n",
    "#data = {'NPOS': np.array([NN_POS_PAIR['NPOS'][0]]*10),'NTERM':w2v_np_result}\n",
    "\n",
    "NN_POS_PAIR.append(pd.DataFrame(data),ignore_index=True)\n",
    "#pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 對 dataframe做 reshape (10,2) --> (2,10)\n",
    "pos_numpy = pd.DataFrame.as_matrix(pp)\n",
    "DATA_STATISTIC_RESHAPE = pd.DataFrame(pos_numpy.reshape(2,-1))\n",
    "DATA_STATISTIC_RESHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN_POS_PAIR['NPOS'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(NN_POS_PAIR_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN_POS_PAIR_EXT = NN_POS_PAIR_EXT.drop_duplicates()\n",
    "NN_POS_PAIR_EXT.sort(['NPOS','NTERM'],ascending=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
